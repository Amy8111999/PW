{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amy8111999/PW/blob/main/chapter_appendix-tools-for-deep-learning/jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "                        ASSINGMENT-1\n",
        "\n",
        "Q.1-> What is the differnce betweeen AI,ML,DL and Data science? provide explanation of each.\n",
        "Ans-> Artificial Intelligence (AI):\n",
        "AI is the broad field of creating machines that can simulate human intelligence — such as reasoning, learning, perception, and decision-making. Example: Chatbots, self-driving cars.\n",
        "Machine Learning (ML):\n",
        "A subset of AI that enables machines to learn patterns from data and improve over time without explicit programming.\n",
        "Data Science:\n",
        "Combines statistics, ML, data visualization, and domain knowledge to extract insights from data.bold text"
      ],
      "metadata": {
        "id": "L8tnhYEU33jO"
      },
      "id": "L8tnhYEU33jO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.2->Explain overfitting and underfitting in ML. How can you detect and prevent them?\n",
        "Ans->Overfitting:\n",
        "The model learns noise and details from the training data, performing well on training but poorly on unseen data.\n",
        "Detection: High training accuracy but low validation accuracy.\n",
        "Prevention:\n",
        "Use cross-validation\n",
        "Apply regularization (L1, L2)\n",
        "Use dropout in neural networks\n",
        "Gather more data or simplify the model\n",
        "Underfitting:\n",
        "The model is too simple to capture data patterns, leading to poor performance on both training and test sets.\n",
        "Detection: Low accuracy on both training and validation sets.\n",
        "Prevention:\n",
        "1.Use a more complex model\n",
        "2.Reduce regularization\n",
        "3.Feature engineering\n",
        "B4.ias-Variance Tradeoff:\n",
        "5.High bias → underfitting; High variance → overfitting. The goal is to balance both."
      ],
      "metadata": {
        "id": "HTN7b9iD5Tfl"
      },
      "id": "HTN7b9iD5Tfl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.3->How would you handle missing values in a dataset? Explain at least three methods with examples.\n",
        "\n",
        "Ans->1. Deletion:Remove rows or columns with missing values.\n",
        "Example: df.dropna()\n",
        "Use only when missing data is small and random.\n",
        "2. Mean/Median/Mode Imputation:Replace missing values with mean (for continuous), median (for skewed), or mode (for categorical).\n",
        "Example: df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "3. Predictive Modeling:Predict missing values using ML models (like regression or KNNImputer).\n",
        "Example: Use KNN imputation to estimate missing data based on similar samples."
      ],
      "metadata": {
        "id": "8AYPe6lh54HM"
      },
      "id": "8AYPe6lh54HM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.4->What is an imbalanced dataset? Describe two techniques to handle it.\n",
        "\n",
        "Ans->Imbalanced Dataset:\n",
        "When one class significantly outnumbers the others in classification problems (e.g., fraud detection, medical diagnosis).\n",
        "\n",
        "\n",
        "Techniques:\n",
        "\n",
        "1. SMOTE (Synthetic Minority Oversampling Technique):\n",
        "Creates synthetic samples of the minority class by interpolating between nearest neighbors.\n",
        "\n",
        "\n",
        "2. Random Undersampling/Oversampling:Undersampling: Remove samples from the majority class.\n",
        "Oversampling: Duplicate or resample minority class samples.\n",
        "Alternative:Use class weights in models to penalize misclassification of minority class."
      ],
      "metadata": {
        "id": "kNtC4OGr6ZR3"
      },
      "id": "kNtC4OGr6ZR3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5->Why is feature scaling important in ML? Compare Min-Max scaling and Standardization.\n",
        "\n",
        "Ans->r: Feature scaling ensures all features contribute equally to model training, especially for distance-based algorithms (KNN, SVM, Gradient Descent).\n",
        "Min-Max Scaling:Scales data to a fixed range [0,1].\n",
        "Formula:X' = \\frac{X - X_{min}}{X_{max} - X_{min}}\n",
        "Standardization (Z-score normalization):Centers data around mean 0 and standard deviation 1.\n",
        "Formula:X' = \\frac{X - \\mu}{\\sigma}"
      ],
      "metadata": {
        "id": "pf-ol03G6vC9"
      },
      "id": "pf-ol03G6vC9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.6->Compare Label Encoding and One-Hot Encoding. When would you prefer one over the other?\n",
        "Ans->Label Encoding:Converts categories into integer labels (e.g., Red=0, Green=1, Blue=2).Use for: Ordinal data (where order matters, e.g., low < medium < high).\n",
        "One-Hot Encoding:Creates binary columns for each category (e.g., [1,0,0], [0,1,0]).Use for: Nominal data (no order, e.g., gender, city).\n",
        "\n"
      ],
      "metadata": {
        "id": "6zYVK8Tv7GSd"
      },
      "id": "6zYVK8Tv7GSd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.7->"
      ],
      "metadata": {
        "id": "mqxPqP_17g8G"
      },
      "id": "mqxPqP_17g8G"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}